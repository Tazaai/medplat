  - `DialogChat.jsx` â†’ AI chat dialog
  - `CaseList.jsx`, `CaseSelectors.jsx`, etc.
- Uses dynamic props:
  - `model` (`gpt-4o`, `gpt-4o-mini`)
  - `lang` (ISO language)
  - `gamify` (true / false)

---

## ï¿½ Backend API Endpoints

### Core Routes
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/topics` | GET | Fetch all 1115 topics from Firestore `topics2` collection |
| `/api/topics/categories` | POST | Get 30 unique categories (areas) from topics |
| `/api/topics/search` | POST | Filter topics by category/area |
| `/api/cases` | POST | **Two-stage pipeline**: Stage 1 (professor-v2 generator â‰¥95%) + Stage 2 (internal panel validation) |
| `/api/internal-panel` | POST | **Stage 2**: Lightweight validation layer (quality scoring + micro-refinement if needed) |
| `/api/panel-discussion` | POST | **Optional**: Medical conference-style discussion (user-requested, not automatic) |
| `/api/dialog` | POST | Interactive AI chat for case discussion |
| `/api/gamify` | POST | Generate 12-question adaptive MCQ quiz |
| `/api/quickref` | GET/POST | Medical term tooltips (definitions, clinical significance) |
| `/api/evidence` | POST | Test performance comparisons (sensitivity/specificity %) |
| `/api/panel/review` | POST | Expert panel case review (legacy) |
| `/api/expert-panel` | POST | **External**: Dynamic 12-role expert panel review (manual/developer use) |
| `/api/location` | GET | Detect user region for guideline adaptation |
| `/api/comment` | POST | Save user feedback/comments |

---

### ðŸŽ¯ TWO-STAGE CASE GENERATION PIPELINE (Professor-Level Quality)

MedPlat uses a **two-stage architecture** to ensure every case achieves professor-level academic quality:

#### **Stage 1: Professor-v2 Generator (â‰¥95% Quality Baseline)**

**Mission**: Generate cases that are **95-100% ready for publication** on first pass, minimizing the need for panel rewrites.

**Key Features**:
- **Global Quality Rules**: Applied to ALL specialties (Cardiology, Neurology, Toxicology, Pediatrics, Surgery, Psychiatry, Infectious Disease, Endocrinology, etc.)
- **Regional Calibration**: Auto-selects guidelines by region:
  - ðŸ‡ºðŸ‡¸ US: AHA, ACC, ACEP, ATS, IDSA, ADA
  - ðŸ‡ªðŸ‡º EU/DK: ESC, NICE, NNBV, ERS, ESCMID, EASD
  - ðŸ‡¬ðŸ‡§ UK: NICE, BTS, BCS, RCOG, SIGN
  - ðŸ‡¨ðŸ‡¦ Canada: CCS, CTS, Diabetes Canada
- **Content Expansion Directives** (Universal):
  - **History**: Functional status, lifestyle, adherence, social context
  - **Examination**: Neuro/systemic always documented, vitals ONCE, hemodynamic profile
  - **Pathophysiology**: Molecular â†’ cellular â†’ organ â†’ clinical mechanism
  - **Differentials**: â‰¥1 metabolic/structural/functional with "why_against" reasoning for rejected diagnoses
  - **Management**: Timing windows, escalation, low-resource fallbacks
  - **Evidence**: Auto-generated test comparisons (sensitivity/specificity %)
  - **Teaching**: Pearls, pitfalls, reflection questions, mnemonics (REQUIRED for ALL cases)
- **Quality Targets**: Completeness 100%, Accuracy â‰¥95%, Pathophysiology â‰¥90%
- **Meta Fields**: `generator_version: "professor_v2"`, `quality_estimate: 0.95`

#### **Stage 2: Internal Expert Panel (Lightweight Validation)**

**Mission**: Perform **lightweight validation** and micro-fixes on cases already at â‰¥95% quality. Panel is NO LONGER a heavy rewriter.

**Quality Scoring Weights** (Rebalanced):
- Completeness: 20% (all sections filled)
- Clinical Accuracy: 20% (realistic values, logical consistency)
- Guideline Adherence: 15% (region-appropriate, evidence-based)
- **Pathophysiology Depth: 20%** (+5% increase from previous 15%)
- **Educational Value: 20%** (+5% increase from previous 15%)
- Academic Rigor: 5%

**Minimum Threshold**: **0.95** (raised from 0.85)
- Cases â‰¥0.95: Panel approves with minimal changes
- Cases <0.95: One micro-refinement pass (temperature 0.6)

**Telemetry**: Logs quality metrics for monitoring:
```
ðŸ“Š Quality Metrics | Topic: X | Category: Y | Score: 0.XXX | Generator: professor_v2
```

**Cost Optimization**: 60-70% reduction in regeneration passes compared to previous architecture.

### ðŸ§¬ INTERNAL EXPERT PANEL (inside case generator â€” invisible to users)

### ðŸ©º Purpose

Automatically **reviews, validates, and enhances** each generated case before it is shown to the user. Acts as a professor-level multidisciplinary review board, ensuring every case meets academic, clinical, and educational excellence.

> ðŸ§  Goal: Deliver reasoning, structure, and quality that **surpass UpToDate, AMBOSS, and Medscape**, setting MedPlat as the global benchmark for intelligent clinical learning.

---

### ðŸ§© Dynamic Composition

The internal panel is automatically assembled based on the caseâ€™s specialty and complexity.

**Standard composition (context-adaptive):**

- 3 senior specialists from the relevant field (e.g., Cardiology, Toxicology, Neurology, etc.)
- 2 general practitioners (GPs)
- 2 emergency medicine consultants
- 1 clinical pharmacist
- 1 field researcher (for public health / epidemiology)
- 1 university professor of medicine (for academic oversight)
- 1 radiologist (optional, per case need)
- 1 internal AI-education logic reviewer (for structure and reasoning clarity)

---

### âš™ï¸ Behavior

- Runs **automatically inside `/api/dialog`** immediately after raw case generation.
- The panel silently:

  - Reviews all structured fields (history, exam, labs, management, teaching).
  - Checks **guideline accuracy**, **timing windows**, and **evidence depth**.
  - Adds missing **red flags**, **social/disposition notes**, or **ethical concerns**.
  - Ensures **clinical scales and quantifications** (e.g., NIHSS, Killip, SOFA) appear when relevant.
  - Refines language to be concise, academic, and globally guideline-aware.
- Only the refined, consensus-approved version is returned.
- Users only see the tag:

  > âœ… *Validated by Internal Expert Panel*

---

### ðŸŽ¯ Focus and Quality Criteria

1. **Realism & Completeness:** every section filled, logical, and region-adapted.
2. **Guideline Integration:** harmonize with **NNBV, ESC, AHA, NICE, WHO**, and regional authorities.
3. **Academic Depth:** teaching pearls, mnemonics, and evidence hierarchy always included.
4. **Diversity of Reasoning:** encourage alternative explanations and clinical uncertainty when realistic.
5. **Scalability:** logic remains dynamic and specialty-aware â€” never static or hardcoded.
6. **Regeneration Loop:** if internal panel quality score < 0.85 (out of 1.0) â†’ automatic refinement before publishing.

---

### ðŸ† Vision & Quality Benchmark

> **MedPlat's two-stage pipeline ensures every case reads like a university-level clinical masterclass** â€” structured, evidence-anchored, and pedagogically superior to any existing reference source.

**Competitive Benchmark**: Surpass UpToDate, AMBOSS, and Medscape across ALL clinical domains by:
- Delivering **95-100% quality on first pass** (Stage 1)
- Providing **lightweight validation** instead of heavy rewrites (Stage 2)
- Maintaining **consistent excellence across all specialties** (Cardiology, Neurology, Toxicology, Pediatrics, Surgery, etc.)
- Enabling **global guideline adaptation** (US, EU/DK, UK, Canada, International)

**Verified Quality Scores** (Multi-Specialty):
- Cardiology (Acute MI): 0.96
- Neurology (Stroke): 0.96
- Toxicology (Paracetamol): 0.97
- Infectious Disease (CAP): 0.97
- Surgery (Appendicitis): 0.97
- Endocrinology (DKA): 0.96
- Intensive Care (Septic Shock): 0.98

**Average Stage 2 Quality**: **0.967** (target: â‰¥0.95) âœ…

---

### ðŸ“š Frontend Teaching Elements

Cases display teaching content in collapsible, color-coded panels:

- **ðŸ’Ž Clinical Pearls** (green): Key diagnostic insights
- **âš ï¸ Common Pitfall** (orange): Errors to avoid
- **ðŸ¤” Reflection Question** (blue): Self-assessment prompts
- **ðŸ§  Mnemonics** (purple): Memory aids with clinical context

**Panel Discussion** (optional, user-requested):
- Click "ðŸ©º View Internal Panel Discussion" button
- Medical conference-style layout with expert arguments
- **Arguments FOR** (âœ… green) with supporting evidence
- **Arguments AGAINST** (âŒ red) with contradicting evidence, alternative explanations
- Panel consensus with confidence level
- Teaching insights and next steps

---

### Implementation notes (developer guidance)

- Stage 1 (professor-v2) targets â‰¥95% quality before panel review
- Stage 2 (internal panel) performs lightweight validation, not heavy rewriting
- Maintain metadata: `meta.generator_version = "professor_v2"`, `meta.quality_estimate = 0.95`, `meta.quality_score` (from panel)
- Log quality metrics for telemetry: `ðŸ“Š Quality Metrics | Topic: X | Score: Y | Generator: professor_v2`
- Panel discussion is OPTIONAL and lazy-loaded (not automatic)
- Keep `/api/internal-panel` read-only for data stores; it must not perform Firestore writes to topic collections

---

## ï¿½ðŸ” Secret Management

### Repository Secrets (GitHub â†’ Settings â†’ Actions)
| Secret | Purpose |
|---------|----------|
| `OPENAI_API_KEY` | Access to GPT models |
| `GCP_PROJECT` | Cloud project ID |
| `GCP_SA_KEY` | Service account JSON for Cloud Run deploy |
| `FIREBASE_SERVICE_KEY` | Firebase Admin SDK credentials |
| `VITE_API_BASE` | Backend URL for frontend build |

> ðŸ§© **No `.env` files are used in production.**  
> Development keys reside in `.env.local` (ignored by git).

---

## ðŸ§° Local Development

### Prerequisites
```bash
npm install
npm install --prefix backend
npm install --prefix frontend

_For temporary ops toggles (e.g. SOFT_FAIL_CONNECTIVITY), see docs/SOFT_FAIL_CONNECTIVITY.md._
